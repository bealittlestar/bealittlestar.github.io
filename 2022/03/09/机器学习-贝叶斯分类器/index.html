<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>机器学习-贝叶斯分类器 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="[TOC] 概率论的知识">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-贝叶斯分类器">
<meta property="og:url" content="http://shiyicherry.github.io/2022/03/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="[TOC] 概率论的知识">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://shiyicherry.github.io/2022/03/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/熵.png">
<meta property="og:image" content="http://shiyicherry.github.io/2022/03/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/2.png">
<meta property="article:published_time" content="2022-03-09T06:46:51.000Z">
<meta property="article:modified_time" content="2023-12-05T11:46:47.131Z">
<meta property="article:author" content="May May">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://shiyicherry.github.io/2022/03/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/熵.png">
  
    <link rel="alternate" href="../../../../atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="../../../../favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="../../../../css/style.css">

  
    
<link rel="stylesheet" href="../../../../fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="../../../../index.html" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="../../../../index.html">Home</a>
        
          <a class="main-nav-link" href="../../../../archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="../../../../atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://shiyicherry.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-机器学习-贝叶斯分类器" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="" class="article-date">
  <time class="dt-published" datetime="2022-03-09T06:46:51.000Z" itemprop="datePublished">2022-03-09</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      机器学习-贝叶斯分类器
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>[TOC]</p>
<h1 id="概率论的知识"><a href="#概率论的知识" class="headerlink" title="概率论的知识"></a>概率论的知识</h1><span id="more"></span>
<h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><script type="math/tex; mode=display">
P(A|B)=P(A\cap B)/P(B)</script><p>已知B发生的概率，求A发生的概率</p>
<script type="math/tex; mode=display">
P(X=x|Y = C_k) = P(X(1)=x(1),X(2)=x(2),..,|Y = C_k)</script><p>如果随机X独立</p>
<script type="math/tex; mode=display">
P(X=x|Y = C_k) = P(X(1)=x(1),X(2)=x(2),..,|Y = C_k)
= \Pi(P(X_i = x_i)|Y = c_i)</script><h2 id="全概率"><a href="#全概率" class="headerlink" title="全概率"></a>全概率</h2><script type="math/tex; mode=display">
P(B) = \sum_{i=1}^{N}P(B \cap A_i)P(A_i)</script><h2 id="贝叶斯推断"><a href="#贝叶斯推断" class="headerlink" title="贝叶斯推断"></a>贝叶斯推断</h2><script type="math/tex; mode=display">
P(A|B)=P(A)\frac{P(B|A)}{P(B)}</script><script type="math/tex; mode=display">
P(A_i|B)=P(A_i)\frac{P(B|A_i)}{\sum P(A_i)P(B|A_i)}</script><p>$P(A)$：Prior probability 先验概率，在B事件发生之前，对A事件做一个判断</p>
<p>$P(A|B)$:Posterior probability 后验概率，在B事件发生之后，对A事件的概率重新评估</p>
<p>$P(B|A)/P(B)$:称为可能性函数，一个调整因子</p>
<p>后验概率=先验概率*调整因子 （可知，调整因此&gt;1,发生概率增大了，</p>
<h1 id="贝叶斯决策论"><a href="#贝叶斯决策论" class="headerlink" title="贝叶斯决策论"></a>贝叶斯决策论</h1><p>英文：Bayesian decision theory</p>
<p>设有$N$种可能的类别, 即γ=${c_1,c_2,…,c_N}$. $λ_ij$是将一个真实类别为$c_j$的样本判为$c_x$的损失。 基于后验概率可得将样本分类所产生的期望损失, 或者成为条件风险(Conditional Risk) </p>
<script type="math/tex; mode=display">
R(C_i|x)=∑_{j=1}^Nλ_{ij}P(c_j|x)</script><p>于是， 我们的任务就是寻找判定准则h， 令$χ→γ$ 使得最小化总体风险，$R(h)=E_x[R(h(x)|x]$最小. 对于每一个$x$，若$h$都能最小化条件风险，那么总体也被最小化了。 可以简化为对每个样本选择其条件风险最小的分类, 即: </p>
<script type="math/tex; mode=display">
h(x)=arg \min_{c⊂λ}R(c|x)</script><p>此$h(x)$就是贝叶斯最优分类器。 $R(h)$为贝叶斯风险(Bayes Risk), $1−R(h)$反映了分类器的最优性能. </p>
<p>具体来说，如果目标是最小化分类错误率，</p>
<script type="math/tex; mode=display">\lambda_{ij}=\begin{cases} 0\ \  i==j\\1 \ \ \ i!=j \end{cases}</script><p>则$R(c|x)=1-p(c|x)$，因此可知，$h(x)=\max_{c\in C} p(c|x)$</p>
<p>对于样本$x$,选择后验概率$P(c|X)$最大的类别为标记。</p>
<p>问题转换为</p>
<script type="math/tex; mode=display">
P(c_i|x)=\frac{P(c_i)P(x|c_i)}{\sum P(x)}</script><p>求先验概率和似然($P(x|c)$)</p>
<p>其中</p>
<p>$P(c)$表达了样本空间种各类样本所占的比列，根据大数定律，当样本足够充分的独立同分布样本是，可以频率估计</p>
<p>$P(x|c)$,涉及关于x所以属性的联合概率，用频率估计概率可能不太好，对于估计类条件概率的一种通用策略是先假设具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。</p>
<p>$P(x|c)$是类条件概率，由某个分布决定，$P(x|\theta_c)$来表示了</p>
<p>频率注意派认为可以通过优化似然函数估计参数。$D_c$类别c的样本集合，独立同分布</p>
<script type="math/tex; mode=display">
P(D_c|\theta_c)=\Pi_{x \in D_c}P(x|\theta_c)</script><script type="math/tex; mode=display">
LL(\theta_c)=log  P(D_c|\theta_c)</script><h1 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h1><p>英文：naive Bayes classifier</p>
<p>假设：属性条件独立性假设，每个属性独立性对分类结果发生影响</p>
<script type="math/tex; mode=display">
P(c|x)=\frac{P(c)P(x|c)}{P(x)}=\frac{P(c)\Pi_{i=1}^{d}P(x_i|c)}{P(x)}</script><p>对于一个$x$，$P(x)$都是相同的，因此贝叶斯模型可写为</p>
<script type="math/tex; mode=display">
h_{nb}(x)=arg max_{c\in y}P(c)\Pi_{i=1}^{d}P(x_i|c)</script><h2 id="计算过程"><a href="#计算过程" class="headerlink" title="计算过程"></a>计算过程</h2><p>假设$D_{c_i}$表示第i类的样本集合，</p>
<ol>
<li><p>$P(c<em>i)=\frac{|D</em>{c_i}|}{|D|}$</p>
</li>
<li><p>如果是离散属性</p>
</li>
</ol>
<script type="math/tex; mode=display">
P(x_i|c_i)=\frac{|D_{c,x_i}|}{|D_{c_i}|}</script><p>如果是连续属性，$P(x<em>i|c_i)$服从$N(u</em>{c,i},\theta_{c,i}^2)$的分布</p>
<script type="math/tex; mode=display">
P(x_i|c)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2})</script><ol>
<li>$P(c<em>i)\Pi</em>{i=1}^{N}P(x_i|c_i)$</li>
</ol>
<p>注意为了避免其他属性携带的信息被训练集中未出现的属性值抹去，因此用拉普拉斯修正（Laplacian correction)</p>
<script type="math/tex; mode=display">
P(c)=\frac{|D_{c_i}|+1}{|D|+N}\\
P(x_i|c)=\frac{|D_{x_i,c}|+1}{|D_c|+N_i}</script><p>$N$:训练集可能出现的类别数</p>
<p>$N_i$:第i个属性可能的取值数</p>
<p>显然，拉普拉斯修正避免因训练集不充分导出的概率估值为0的情况</p>
<h1 id="朴素贝叶斯的种类"><a href="#朴素贝叶斯的种类" class="headerlink" title="朴素贝叶斯的种类"></a>朴素贝叶斯的种类</h1><p>再scikit-learn中，一共有三个朴素贝叶斯，分别是</p>
<h2 id="GaussianNB"><a href="#GaussianNB" class="headerlink" title="GaussianNB"></a>GaussianNB</h2><script type="math/tex; mode=display">
P(x_i|C_i)=\frac{1}{\sqrt{2\pi}\theta_{c,i}}exp(-\frac{(x_i-u_i)^2}{2\theta_{c,i}^2})</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入包</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris=datasets.load_iris()</span><br><span class="line"><span class="comment">#切分数据集</span></span><br><span class="line">Xtrain, Xtest, ytrain, ytest = train_test_split(iris.data,</span><br><span class="line">                                                iris.target,</span><br><span class="line">                                                random_state=<span class="number">42</span>)</span><br><span class="line"><span class="comment">#建模</span></span><br><span class="line">clf = GaussianNB()</span><br><span class="line">clf.fit(Xtrain, ytrain)</span><br><span class="line"></span><br><span class="line"><span class="comment">#在测试集上执行预测，proba导出的是每个样本属于某类的概率</span></span><br><span class="line">clf.predict(Xtest)</span><br><span class="line">clf.predict_proba(Xtest) <span class="comment">#每一类计算结果都输出</span></span><br><span class="line"><span class="comment">#测试准确率</span></span><br><span class="line">accuracy_score(ytest, clf.predict(Xtest))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">dataSet =pd.read_csv(<span class="string">&#x27;iris.txt&#x27;</span>,header = <span class="literal">None</span>)</span><br><span class="line">dataSet.head()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">randSplit</span>(<span class="params">dataSet, rate</span>):</span><br><span class="line">    l = <span class="built_in">list</span>(dataSet.index) <span class="comment">#提取出索引</span></span><br><span class="line">    random.shuffle(l) <span class="comment">#随机打乱索引</span></span><br><span class="line">    dataSet.index = l <span class="comment">#将打乱后的索引重新赋值给原数据集</span></span><br><span class="line">    n = dataSet.shape[<span class="number">0</span>] <span class="comment">#总行数</span></span><br><span class="line">    m = <span class="built_in">int</span>(n * rate) <span class="comment">#训练集的数量</span></span><br><span class="line">    train = dataSet.loc[<span class="built_in">range</span>(m), :] <span class="comment">#提取前m个记录作为训练集</span></span><br><span class="line">    test = dataSet.loc[<span class="built_in">range</span>(m, n), :] <span class="comment">#剩下的作为测试集</span></span><br><span class="line">    dataSet.index = <span class="built_in">range</span>(dataSet.shape[<span class="number">0</span>]) <span class="comment">#更新原数据集的索引</span></span><br><span class="line">    test.index = <span class="built_in">range</span>(test.shape[<span class="number">0</span>]) <span class="comment">#更新测试集的索引</span></span><br><span class="line"></span><br><span class="line">train,test=randSplit(dataSet, <span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gnb_classify</span>(<span class="params">train,test</span>):</span><br><span class="line">    labels = train.iloc[:,-<span class="number">1</span>].value_counts().index <span class="comment">#提取训练集的标签种类</span></span><br><span class="line">    mean =[] <span class="comment">#存放每个类别的均值</span></span><br><span class="line">    std =[] <span class="comment">#存放每个类别的方差</span></span><br><span class="line">    result = [] <span class="comment">#存放测试集的预测结果</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> labels:</span><br><span class="line">        item = train.loc[train.iloc[:,-<span class="number">1</span>]==i,:] <span class="comment">#分别提取出每一种类别</span></span><br><span class="line">        m = item.iloc[:,:-<span class="number">1</span>].mean() <span class="comment">#当前类别的平均值</span></span><br><span class="line">        s = np.<span class="built_in">sum</span>((item.iloc[:,:-<span class="number">1</span>]-m)**<span class="number">2</span>)/(item.shape[<span class="number">0</span>]) <span class="comment">#当前类别的方差</span></span><br><span class="line">        mean.append(m) <span class="comment">#将当前类别的平均值追加至列表</span></span><br><span class="line">        std.append(s) <span class="comment">#将当前类别的方差追加至列表</span></span><br><span class="line">    means = pd.DataFrame(mean,index=labels) <span class="comment">#变成DF格式，索引为类标签</span></span><br><span class="line">    stds = pd.DataFrame(std,index=labels) <span class="comment">#变成DF格式，索引为类标签</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(test.shape[<span class="number">0</span>]):</span><br><span class="line">        iset = test.iloc[j,:-<span class="number">1</span>].tolist() <span class="comment">#当前测试实例</span></span><br><span class="line">        iprob = np.exp(-<span class="number">1</span>*(iset-means)**<span class="number">2</span>/(stds*<span class="number">2</span>))/(np.sqrt(<span class="number">2</span>*np.pi*stds)) <span class="comment">#正态分布公式</span></span><br><span class="line">        prob = train.iloc[:,-<span class="number">1</span>].value_counts()/<span class="built_in">len</span>(train.iloc[:,-<span class="number">1</span>]) <span class="comment">#初始化当前实例总概率</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(test.shape[<span class="number">1</span>]-<span class="number">1</span>): <span class="comment">#遍历每个特征</span></span><br><span class="line">            prob *= iprob[k] <span class="comment">#特征概率之积即为当前实例概率</span></span><br><span class="line">        cla = prob.index[np.argmax(prob.values)] <span class="comment">#返回最大概率的类别</span></span><br><span class="line">        result.append(cla)</span><br><span class="line">    test[<span class="string">&#x27;predict&#x27;</span>]=result</span><br><span class="line">    acc = (test.iloc[:,-<span class="number">1</span>]==test.iloc[:,-<span class="number">2</span>]).mean() <span class="comment">#计算预测准确率</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;模型预测准确率为<span class="subst">&#123;acc&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> test</span><br><span class="line"></span><br><span class="line">gnb_classify(train,test)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    train,test= randSplit(dataSet, <span class="number">0.8</span>)</span><br><span class="line">    gnb_classify(train,test)</span><br><span class="line">   </span><br></pre></td></tr></table></figure>
<h2 id="MultinomialNB"><a href="#MultinomialNB" class="headerlink" title="MultinomialNB"></a>MultinomialNB</h2><p>先验概率多项式分布的朴素贝叶斯，假设特征是由一共简单多项式分布生成，多项分布可以描述各种类型样本出现的频率，该模型常用于文本分类，特别表示次数。$\lambda$常取值1</p>
<script type="math/tex; mode=display">
P(x_{il}|c)=\frac{x_{il}+\lambda}{m_k+n\lambda}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loadDataSet</span>():</span><br><span class="line">    dataSet=[[<span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;has&#x27;</span>, <span class="string">&#x27;flea&#x27;</span>, <span class="string">&#x27;problems&#x27;</span>, <span class="string">&#x27;help&#x27;</span>, <span class="string">&#x27;please&#x27;</span>],</span><br><span class="line">             [<span class="string">&#x27;maybe&#x27;</span>, <span class="string">&#x27;not&#x27;</span>, <span class="string">&#x27;take&#x27;</span>, <span class="string">&#x27;him&#x27;</span>, <span class="string">&#x27;to&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;park&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>],</span><br><span class="line">             [<span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dalmation&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;so&#x27;</span>, <span class="string">&#x27;cute&#x27;</span>, <span class="string">&#x27;I&#x27;</span>, <span class="string">&#x27;love&#x27;</span>, <span class="string">&#x27;him&#x27;</span>],</span><br><span class="line">             [<span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;posting&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>, <span class="string">&#x27;worthless&#x27;</span>, <span class="string">&#x27;garbage&#x27;</span>],</span><br><span class="line">             [<span class="string">&#x27;mr&#x27;</span>, <span class="string">&#x27;licks&#x27;</span>, <span class="string">&#x27;ate&#x27;</span>, <span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;steak&#x27;</span>, <span class="string">&#x27;how&#x27;</span>, <span class="string">&#x27;to&#x27;</span>, <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;him&#x27;</span>],</span><br><span class="line">             [<span class="string">&#x27;quit&#x27;</span>, <span class="string">&#x27;buying&#x27;</span>, <span class="string">&#x27;worthless&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;food&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>]] <span class="comment">#切分好的词条</span></span><br><span class="line">    classVec = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>] <span class="comment">#类别标签向量，1代表侮辱性词汇，0代表非侮辱性词汇</span></span><br><span class="line">    <span class="keyword">return</span> dataSet,classVec</span><br><span class="line">dataSet,classVec = loadDataSet()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">createVocabList</span>(<span class="params">dataSet</span>):</span><br><span class="line">    vocabSet = <span class="built_in">set</span>() <span class="comment">#创建一个空的集合</span></span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> dataSet: <span class="comment">#遍历dataSet中的每一条言论</span></span><br><span class="line">        vocabSet = vocabSet | <span class="built_in">set</span>(doc) <span class="comment">#取并集</span></span><br><span class="line">        vocabList = <span class="built_in">list</span>(vocabSet)</span><br><span class="line">    <span class="keyword">return</span> vocabList</span><br><span class="line"></span><br><span class="line">vocabList = createVocabList(dataSet)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">setOfWords2Vec</span>(<span class="params">vocabList, inputSet</span>):</span><br><span class="line">    returnVec = [<span class="number">0</span>] * <span class="built_in">len</span>(vocabList) <span class="comment">#创建一个其中所含元素都为0的向量</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet: <span class="comment">#遍历每个词条</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList: <span class="comment">#如果词条存在于词汇表中，则变为1</span></span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot; <span class="subst">&#123;word&#125;</span> is not in my Vocabulary!&quot;</span> )</span><br><span class="line">    <span class="keyword">return</span> returnVec <span class="comment">#返回文档向量</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_trainMat</span>(<span class="params">dataSet</span>):</span><br><span class="line">    trainMat = [] <span class="comment">#初始化向量列表</span></span><br><span class="line">    vocabList = createVocabList(dataSet) <span class="comment">#生成词汇表</span></span><br><span class="line">    <span class="keyword">for</span> inputSet <span class="keyword">in</span> dataSet: <span class="comment">#遍历样本词条中的每一条样本</span></span><br><span class="line">        returnVec=setOfWords2Vec(vocabList, inputSet) <span class="comment">#将当前词条向量化</span></span><br><span class="line">        trainMat.append(returnVec) <span class="comment">#追加到向量列表中</span></span><br><span class="line">    <span class="keyword">return</span> trainMat</span><br><span class="line">trainMat = get_trainMat(dataSet)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">trainNB</span>(<span class="params">trainMat,classVec</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(trainMat) <span class="comment">#计算训练的文档数目</span></span><br><span class="line">    m = <span class="built_in">len</span>(trainMat[<span class="number">0</span>]) <span class="comment">#计算每篇文档的词条数</span></span><br><span class="line">    pAb = <span class="built_in">sum</span>(classVec)/n <span class="comment">#文档属于侮辱类的概率</span></span><br><span class="line">    p0Num = np.zeros(m) <span class="comment">#词条出现数初始化为0</span></span><br><span class="line">    p1Num = np.zeros(m) <span class="comment">#词条出现数初始化为0</span></span><br><span class="line">    p0Denom = <span class="number">0</span> <span class="comment">#分母初始化为0</span></span><br><span class="line">    p1Denom = <span class="number">0</span> <span class="comment">#分母初始化为0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): <span class="comment">#遍历每一个文档</span></span><br><span class="line">        <span class="keyword">if</span> classVec[i] == <span class="number">1</span>: <span class="comment">#统计属于侮辱类的条件概率所需的数据</span></span><br><span class="line">            p1Num += trainMat[i]</span><br><span class="line">            p1Denom += <span class="built_in">sum</span>(trainMat[i])</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment">#统计属于非侮辱类的条件概率所需的数据</span></span><br><span class="line">            p0Num += trainMat[i]</span><br><span class="line">            p0Denom += <span class="built_in">sum</span>(trainMat[i])</span><br><span class="line">    p1V = p1Num/p1Denom</span><br><span class="line">    p0V = p0Num/p0Denom</span><br><span class="line">    <span class="keyword">return</span> p0V,p1V,pAb <span class="comment">#返回属于非侮辱类,侮辱类和文档属于侮辱类的概率</span></span><br><span class="line"></span><br><span class="line">p0V,p1V,pAb=trainNB(trainMat,classVec)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classifyNB</span>(<span class="params">vec2Classify, p0V, p1V, pAb</span>):</span><br><span class="line">    p1 = reduce(<span class="keyword">lambda</span> x,y:x*y, vec2Classify * p1V) * pAb   <span class="comment">#对应元素相乘</span></span><br><span class="line">    p0 = reduce(<span class="keyword">lambda</span> x,y:x*y, vec2Classify * p0V) * (<span class="number">1</span> - pAb)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;p0:&#x27;</span>,p0)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;p1:&#x27;</span>,p1)</span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">testingNB</span>(<span class="params">testVec</span>):</span><br><span class="line">    dataSet,classVec = loadDataSet() <span class="comment">#创建实验样本</span></span><br><span class="line">    vocabList = createVocabList(dataSet) <span class="comment">#创建词汇表</span></span><br><span class="line">    trainMat= get_trainMat(dataSet) <span class="comment">#将实验样本向量化</span></span><br><span class="line">    p0V,p1V,pAb = trainNB(trainMat,classVec) <span class="comment">#训练朴素贝叶斯分类器</span></span><br><span class="line">    thisone = setOfWords2Vec(vocabList, testVec) <span class="comment">#测试样本向量化</span></span><br><span class="line">    <span class="keyword">if</span> classifyNB(thisone,p0V,p1V,pAb):</span><br><span class="line">        <span class="built_in">print</span>(testVec,<span class="string">&#x27;属于侮辱类&#x27;</span>) <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(testVec,<span class="string">&#x27;属于非侮辱类&#x27;</span>) <span class="comment">#执行分类并打印分类结果</span></span><br><span class="line">        </span><br><span class="line">testVec1 = [<span class="string">&#x27;love&#x27;</span>, <span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dalmation&#x27;</span>]</span><br><span class="line">testingNB(testVec1)</span><br></pre></td></tr></table></figure>
<h2 id="BernoulliNB"><a href="#BernoulliNB" class="headerlink" title="BernoulliNB"></a>BernoulliNB</h2><p>伯努利分布，如果是二元伯努利分布</p>
<script type="math/tex; mode=display">
P(x_{il}|C_i)=P(i|Y=C_i)x_{il}+(1-P(i|Y=C_i))(1-x_{il})</script><p>如果样本属性大多数属于连续，GaussionNB</p>
<p>如果是离散值，使用MultinomialNB</p>
<p>如果样本特征是二元离散值或者稀疏离散值，BernoulliNB</p>
<h1 id="半朴素贝叶斯"><a href="#半朴素贝叶斯" class="headerlink" title="半朴素贝叶斯"></a>半朴素贝叶斯</h1><h2 id="信息量、熵、联合熵、条件熵、互信息"><a href="#信息量、熵、联合熵、条件熵、互信息" class="headerlink" title="信息量、熵、联合熵、条件熵、互信息"></a>信息量、熵、联合熵、条件熵、互信息</h2><h3 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h3><p>反应了随机变量取某个值含的可能性大小，或者是含有的信息多少</p>
<script type="math/tex; mode=display">
I(X=x)=-log_2^{p(x）}</script><h3 id="熵-entropy"><a href="#熵-entropy" class="headerlink" title="熵(entropy)"></a>熵(entropy)</h3><p>反应了信源平均每个符号的信息量,或者是随机变量不确定性的衡量</p>
<script type="math/tex; mode=display">
H(X)=E(I(X))=\sum p(X=x)(-log_2^{p(x)})</script><h2 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h2><p>反应了多个随机变量的平均信息量</p>
<script type="math/tex; mode=display">
H(X,Y)=\sum p(x,y)(-log_2^{p(x,y)})</script><h3 id="条件熵（Conditional-entropy）"><a href="#条件熵（Conditional-entropy）" class="headerlink" title="条件熵（Conditional entropy）"></a>条件熵（Conditional entropy）</h3><p>反应了已知一个随机变量下，另一个随机变量的不确定性</p>
<script type="math/tex; mode=display">
H(X|Y)=-\sum p(y)H(X|Y=y)=-\sum p(x,y)log_2^{p(x|y)}</script><h3 id="互信息-mutual-information"><a href="#互信息-mutual-information" class="headerlink" title="互信息(mutual information)"></a>互信息(mutual information)</h3><p>反应了已知一个随机变量的情况下，另外一个随机变量不确定性减少了多少,可以把互信息看成由于知道 y 值而造成的 x 的不确定性的减小</p>
<script type="math/tex; mode=display">
I(X;Y)=\sum \sum p(x,y)log(\frac{p(x,y)}{p(x)p(y)})\\
=H(X)-H(X|Y)=H(Y)-H(Y|X)</script><p>如果两个随机变量独立，则互信息为0,因此，互信息可以衡量两个随机变量的相关程度</p>
<h2 id="条件互信息"><a href="#条件互信息" class="headerlink" title="条件互信息"></a>条件互信息</h2><p>在条件z发生时的条件互信息</p>
<script type="math/tex; mode=display">
I(X;Y|Z) = \sum\sum p(x,y|z)log_2^{\frac{p(x,y|z)}{p(x|z)p(y|z)}}</script><p><img src="/2022/03/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/熵.png" alt></p>
<h2 id="半朴素贝叶斯-1"><a href="#半朴素贝叶斯-1" class="headerlink" title="半朴素贝叶斯"></a>半朴素贝叶斯</h2><p>适当的考虑一部分属性间的相互依赖关系，这个关系可以用互信息描述</p>
<h3 id="独依赖"><a href="#独依赖" class="headerlink" title="独依赖"></a>独依赖</h3><p>假设每个属性只有一个其他 的属性.则计算公式改下如下</p>
<script type="math/tex; mode=display">
p(C)\Pi_{i=1}^{d} P(x_i|C_i,pa_i)</script><p>$pa_i$是属性$x_i$所依赖的属性，被称为$x_i$的父属性</p>
<p>1)  <strong>SPODE </strong>最简单的方法是：都选一个属性作为父属性</p>
<p>可以通过交叉验证的方法</p>
<p>2)  TAN :最大带权生成树</p>
<p>权重：当y划分为$c_k$类时条件熵</p>
<script type="math/tex; mode=display">
I(x_i;y_i|y)=\sum_{x_i,y_i,c_k}p(x_i,y_j|c_k)log^{\frac{p(x_i;y_j|c_k)}{p(x_i|c_k)p(y_i|c_k)}}</script><p>step 1: 计算任意两个属性之间条件互信息</p>
<script type="math/tex; mode=display">
I(X;Y|Y)=\sum_{i}I(X;Y|c_i)</script><p>step 2: 以属性为结点构建完全图</p>
<p>step 3: 最大带权生成树，挑选根变量</p>
<p>step 4: 加入类别结点y,增加到每个属性的有向边</p>
<p>条件互信息反应了属性在已知类别下的相关性大小</p>
<p><img src="/2022/03/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/2.png" alt></p>
<h2 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h2><p>AODE选择模型尝试将每个属性作为超父构建SPODE</p>
<script type="math/tex; mode=display">
P(c_i|X)正比于 \sum_{i=1,|D_{x_i}>=m}p(c,x_i)\Pi_{j=1}^{d}p(x_j|c_i,x_i)</script><p>$m$通常取30,</p>
<script type="math/tex; mode=display">
P(c,x_i)=\frac{|D_{c,x_i}|+1}{|{D}|+N*N_i}\\
P(x_j|c,x_i)=\frac{|D_{c,x_i,x_j}+1|}{|D_{c,xi}|+N_j}</script><h1 id="贝叶斯网-Bayesian-network"><a href="#贝叶斯网-Bayesian-network" class="headerlink" title="贝叶斯网(Bayesian network)"></a>贝叶斯网(Bayesian network)</h1><p>借助有向无环图来刻画属性之间的依赖关系，条件概率表来描述属性的联合概率分布。</p>
<p>一个贝叶斯网络$B$,包括结构$G$和参数$\Theta$ ,$B(G,\Theta)$,如果两个属性有直接依赖关系，用边连接，对于属性$x<em>i$,其父节点集合$G_i$,则$\Theta$包括每个属性条件概率$\Theta</em>{x_i|\pi_i}=P_B(x_i|\pi_i)$</p>
<h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><script type="math/tex; mode=display">
p(x_1,x_2,...,x_n)=\Pi_{i=1}^{n}p_{B}(x_i|\pi_i)=\Pi_{i=1}^{d}\Theta_{xi|\pi_i}\\
=\Pi_{i=1}^{d}P(x_i|Parents(x_i))</script><h2 id="推断"><a href="#推断" class="headerlink" title="推断"></a>推断</h2><p>一旦训练好贝叶斯网后，就能回答query,通过一些属性的观测者来推断其他属性变量的取值，其中，已知变量的值观测推测待查询的过程“推断”,已知变量的观测者”证据“</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shiyicherry.github.io/2022/03/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/" data-id="clv89aflv00937cvk45nlghz3" data-title="机器学习-贝叶斯分类器" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习-回归分析
        
      </div>
    </a>
  
  
    <a href="../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-SVM/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习-SVM</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Book/">Book</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Categories/">Categories</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/Deep-Learning/">Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/R/">R</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/machine-learning/">machine learning</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E5%A8%B1%E4%B9%90%E7%94%9F%E6%B4%BB/">娱乐生活</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E5%AD%A6%E4%B9%A0%E3%81%AE%E5%8E%86%E7%A8%8B-Journal-of-Studying/">学习の历程(Journal of Studying)</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E5%BF%83%E5%BE%97/">心得</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%80%9D%E7%BB%B4/">思维</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E5%AD%A6/">数学</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/">数据可视化</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6-Data-Science/">数据科学(Data Science)</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/">数理统计</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E5%AD%A6/">数学</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%9D%82%E9%A1%B9/">杂项</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E7%A7%91%E6%99%AE/">科普</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E7%A7%91%E7%A0%94/">科研</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E7%AB%9E%E8%B5%9B/">竞赛</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E8%8B%B1%E8%AF%AD/">英语</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0/">视频学习</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/">计量经济学</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E8%AF%BB%E4%B9%A6%E6%97%A5%E5%B8%B8/">读书日常</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/1/" rel="tag">1</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/BI/" rel="tag">BI</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/BP/" rel="tag">BP</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Boosting-AdaBoost/" rel="tag">Boosting, AdaBoost</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Categories/" rel="tag">Categories</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Daily/" rel="tag">Daily</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Data-Mining/" rel="tag">Data Mining</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Deep-learning/" rel="tag">Deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/English/" rel="tag">English</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Excel/" rel="tag">Excel</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Numpuy/" rel="tag">Numpuy</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Pandas/" rel="tag">Pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/R/" rel="tag">R</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/SQL/" rel="tag">SQL</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/SVD/" rel="tag">SVD</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/deep-learning/" rel="tag">deep learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/df/" rel="tag">df</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/ielts/" rel="tag">ielts</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/logisitics-regression/" rel="tag">logisitics regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/machine-learning/" rel="tag">machine learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/origin/" rel="tag">origin</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/tensorlow/" rel="tag">tensorlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/test/" rel="tag">test</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92/" rel="tag">二次规划</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/" rel="tag">交叉验证</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/" rel="tag">假设检验</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99/" rel="tag">关联规则</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%86%B3%E7%AD%96%E6%A0%91/" rel="tag">决策树</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%8D%95%E8%AF%8D/" rel="tag">单词</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%8D%A1%E6%96%B9%E5%88%86/" rel="tag">卡方分</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag">可视化</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" rel="tag">回归分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%9B%9E%E5%BD%92%E6%A0%91/" rel="tag">回归树</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%AE%89%E6%8E%92/" rel="tag">安排</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D/" rel="tag">希腊字母</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%BD%92%E4%B8%80%E5%8C%96/" rel="tag">归一化</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%BD%A9%E9%93%85/" rel="tag">彩铅</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%80%9D%E7%BB%B4/" rel="tag">思维</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%88%91%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag">我的读书笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%8A%80%E8%83%BD/" rel="tag">技能</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0/" rel="tag">抽样分布函数</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" rel="tag">支持向量机</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E5%9B%9E%E5%BD%92/" rel="tag">支持向量机回归</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD/" rel="tag">数据分析技能</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="tag">数据挖掘</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/" rel="tag">数据探索</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%96%B9%E6%B3%95/" rel="tag">方法</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%96%B9%E6%B3%95%E8%AE%BA/" rel="tag">方法论</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%97%A5%E5%B8%B8/" rel="tag">日常</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%A0%87%E5%87%86%E5%8C%96/" rel="tag">标准化</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%AD%A3%E5%88%99%E5%8C%96/" rel="tag">正则化</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag">特征工程</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag">监督学习与非监督学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%A4%BE%E4%BC%9A%E7%A7%91%E5%AD%A6/" rel="tag">社会科学</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%A7%91%E7%A0%94/" rel="tag">科研</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7/" rel="tag">科研工具</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0/" rel="tag">科研笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%AB%9E%E8%B5%9B/" rel="tag">竞赛</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%BB%98%E5%9B%BE/" rel="tag">绘图</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/" rel="tag">统计学</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E8%83%BD%E5%8A%9B/" rel="tag">能力</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/" rel="tag">西瓜书</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/" rel="tag">计量经济学</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E8%AF%BB%E4%B9%A6/" rel="tag">读书</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/" rel="tag">贝叶斯分类器</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E8%B7%AF%E7%BA%BF/" rel="tag">路线</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E8%BF%90%E8%90%A5/" rel="tag">运营</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E9%9B%85%E6%80%9D/" rel="tag">雅思</a></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E9%A1%B9%E7%9B%AE/" rel="tag">项目</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="../../../../tags/1/" style="font-size: 10px;">1</a> <a href="../../../../tags/BI/" style="font-size: 12px;">BI</a> <a href="../../../../tags/BP/" style="font-size: 10px;">BP</a> <a href="../../../../tags/Boosting-AdaBoost/" style="font-size: 10px;">Boosting, AdaBoost</a> <a href="../../../../tags/Categories/" style="font-size: 10px;">Categories</a> <a href="../../../../tags/Daily/" style="font-size: 12px;">Daily</a> <a href="../../../../tags/Data-Mining/" style="font-size: 10px;">Data Mining</a> <a href="../../../../tags/Deep-learning/" style="font-size: 16px;">Deep learning</a> <a href="../../../../tags/English/" style="font-size: 10px;">English</a> <a href="../../../../tags/Excel/" style="font-size: 10px;">Excel</a> <a href="../../../../tags/Numpuy/" style="font-size: 10px;">Numpuy</a> <a href="../../../../tags/Pandas/" style="font-size: 10px;">Pandas</a> <a href="../../../../tags/Python/" style="font-size: 16px;">Python</a> <a href="../../../../tags/R/" style="font-size: 10px;">R</a> <a href="../../../../tags/SQL/" style="font-size: 12px;">SQL</a> <a href="../../../../tags/SVD/" style="font-size: 10px;">SVD</a> <a href="../../../../tags/deep-learning/" style="font-size: 10px;">deep learning</a> <a href="../../../../tags/df/" style="font-size: 10px;">df</a> <a href="../../../../tags/ielts/" style="font-size: 10px;">ielts</a> <a href="../../../../tags/linux/" style="font-size: 10px;">linux</a> <a href="../../../../tags/logisitics-regression/" style="font-size: 10px;">logisitics regression</a> <a href="../../../../tags/machine-learning/" style="font-size: 12px;">machine learning</a> <a href="../../../../tags/origin/" style="font-size: 10px;">origin</a> <a href="../../../../tags/python/" style="font-size: 10px;">python</a> <a href="../../../../tags/tensorlow/" style="font-size: 10px;">tensorlow</a> <a href="../../../../tags/test/" style="font-size: 10px;">test</a> <a href="../../../../tags/%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92/" style="font-size: 10px;">二次规划</a> <a href="../../../../tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/" style="font-size: 10px;">交叉验证</a> <a href="../../../../tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/" style="font-size: 10px;">假设检验</a> <a href="../../../../tags/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99/" style="font-size: 10px;">关联规则</a> <a href="../../../../tags/%E5%86%B3%E7%AD%96%E6%A0%91/" style="font-size: 10px;">决策树</a> <a href="../../../../tags/%E5%8D%95%E8%AF%8D/" style="font-size: 10px;">单词</a> <a href="../../../../tags/%E5%8D%A1%E6%96%B9%E5%88%86/" style="font-size: 10px;">卡方分</a> <a href="../../../../tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" style="font-size: 12px;">可视化</a> <a href="../../../../tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" style="font-size: 10px;">回归分析</a> <a href="../../../../tags/%E5%9B%9E%E5%BD%92%E6%A0%91/" style="font-size: 10px;">回归树</a> <a href="../../../../tags/%E5%AE%89%E6%8E%92/" style="font-size: 10px;">安排</a> <a href="../../../../tags/%E5%B8%8C%E8%85%8A%E5%AD%97%E6%AF%8D/" style="font-size: 10px;">希腊字母</a> <a href="../../../../tags/%E5%BD%92%E4%B8%80%E5%8C%96/" style="font-size: 10px;">归一化</a> <a href="../../../../tags/%E5%BD%A9%E9%93%85/" style="font-size: 10px;">彩铅</a> <a href="../../../../tags/%E6%80%9D%E7%BB%B4/" style="font-size: 18px;">思维</a> <a href="../../../../tags/%E6%88%91%E7%9A%84%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">我的读书笔记</a> <a href="../../../../tags/%E6%8A%80%E8%83%BD/" style="font-size: 10px;">技能</a> <a href="../../../../tags/%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0/" style="font-size: 10px;">抽样分布函数</a> <a href="../../../../tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" style="font-size: 10px;">支持向量机</a> <a href="../../../../tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E5%9B%9E%E5%BD%92/" style="font-size: 10px;">支持向量机回归</a> <a href="../../../../tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 20px;">数据分析</a> <a href="../../../../tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%80%E8%83%BD/" style="font-size: 10px;">数据分析技能</a> <a href="../../../../tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" style="font-size: 10px;">数据挖掘</a> <a href="../../../../tags/%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2/" style="font-size: 10px;">数据探索</a> <a href="../../../../tags/%E6%96%B9%E6%B3%95/" style="font-size: 10px;">方法</a> <a href="../../../../tags/%E6%96%B9%E6%B3%95%E8%AE%BA/" style="font-size: 10px;">方法论</a> <a href="../../../../tags/%E6%97%A5%E5%B8%B8/" style="font-size: 10px;">日常</a> <a href="../../../../tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 12px;">机器学习</a> <a href="../../../../tags/%E6%A0%87%E5%87%86%E5%8C%96/" style="font-size: 10px;">标准化</a> <a href="../../../../tags/%E6%AD%A3%E5%88%99%E5%8C%96/" style="font-size: 10px;">正则化</a> <a href="../../../../tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">深度学习</a> <a href="../../../../tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" style="font-size: 10px;">特征工程</a> <a href="../../../../tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;">监督学习与非监督学习</a> <a href="../../../../tags/%E7%A4%BE%E4%BC%9A%E7%A7%91%E5%AD%A6/" style="font-size: 10px;">社会科学</a> <a href="../../../../tags/%E7%A7%91%E7%A0%94/" style="font-size: 14px;">科研</a> <a href="../../../../tags/%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7/" style="font-size: 10px;">科研工具</a> <a href="../../../../tags/%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">科研笔记</a> <a href="../../../../tags/%E7%AB%9E%E8%B5%9B/" style="font-size: 10px;">竞赛</a> <a href="../../../../tags/%E7%AE%97%E6%B3%95/" style="font-size: 10px;">算法</a> <a href="../../../../tags/%E7%BB%98%E5%9B%BE/" style="font-size: 10px;">绘图</a> <a href="../../../../tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/" style="font-size: 14px;">统计学</a> <a href="../../../../tags/%E8%83%BD%E5%8A%9B/" style="font-size: 10px;">能力</a> <a href="../../../../tags/%E8%A5%BF%E7%93%9C%E4%B9%A6/" style="font-size: 10px;">西瓜书</a> <a href="../../../../tags/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6/" style="font-size: 12px;">计量经济学</a> <a href="../../../../tags/%E8%AF%BB%E4%B9%A6/" style="font-size: 10px;">读书</a> <a href="../../../../tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/" style="font-size: 10px;">贝叶斯分类器</a> <a href="../../../../tags/%E8%B7%AF%E7%BA%BF/" style="font-size: 10px;">路线</a> <a href="../../../../tags/%E8%BF%90%E8%90%A5/" style="font-size: 10px;">运营</a> <a href="../../../../tags/%E9%9B%85%E6%80%9D/" style="font-size: 10px;">雅思</a> <a href="../../../../tags/%E9%A1%B9%E7%9B%AE/" style="font-size: 10px;">项目</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2023/09/">September 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2022/10/">October 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2022/09/">September 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2022/07/">July 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2021/12/">December 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2021/08/">August 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2020/11/">November 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2020/09/">September 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2020/08/">August 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2020/07/">July 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2020/06/">June 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2020/05/">May 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/12/">December 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/11/">November 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/05/">May 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2019/02/">February 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="../../../../2024/01/31/%E5%AD%A6%E4%B9%A0Daily-2023/">学习Daily-2023</a>
          </li>
        
          <li>
            <a href="../../../../2023/12/24/%E6%94%BF%E6%B2%BB%E7%BB%8F%E6%B5%8E%E5%AD%A6/">政治经济学</a>
          </li>
        
          <li>
            <a href="../../../../2023/12/13/0-%E6%80%A7%E5%88%ABframework/">0-性别framework</a>
          </li>
        
          <li>
            <a href="../../../../2023/12/06/%E7%A7%91%E7%A0%94-%E4%B8%93%E4%B8%9A%E8%AF%8D%E6%B1%87/">科研-专业词汇</a>
          </li>
        
          <li>
            <a href="../../../../2023/12/05/%E5%AE%8F%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E7%BB%8F%E6%B5%8E%E5%91%A8%E6%9C%9F%E7%90%86%E8%AE%BA/">宏观经济学-经济周期理论</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 May May<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="../../../../index.html" class="mobile-nav-link">Home</a>
  
    <a href="../../../../archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="../../../../js/jquery-3.4.1.min.js"></script>



  
<script src="../../../../fancybox/jquery.fancybox.min.js"></script>




<script src="../../../../js/script.js"></script>





  </div>
</body>
</html>